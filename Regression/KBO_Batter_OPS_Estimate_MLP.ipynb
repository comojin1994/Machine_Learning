{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "\n",
    "import os, time, itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경로확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sungjinkim/Documents/Study/Regression_Project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batter = pd.read_csv('./Data/Regular_Season_Batter.csv')\n",
    "\n",
    "batter['Age'] = batter['year'] - batter['year_born'].apply(lambda x: int(x[:4]))\n",
    "\n",
    "batter['height/weight'] = batter['height/weight'].fillna('0cm/0kg')\n",
    "\n",
    "batter['height'] = batter['height/weight'].apply(lambda x: int(x.split('/')[0][:-2]))\n",
    "batter['weight'] = batter['height/weight'].apply(lambda x: int(x.split('/')[1][:-2]))\n",
    "\n",
    "mean_h = np.mean(batter['height'][batter['height'] != 0])\n",
    "mean_w = np.mean(batter['weight'][batter['weight'] != 0])\n",
    "\n",
    "batter['height'] = batter['height'].apply(lambda x: mean_h if x == 0 else x)\n",
    "batter['weight'] = batter['weight'].apply(lambda x: mean_w if x == 0 else x)\n",
    "\n",
    "batter = batter[batter['AB'] >= 396]\n",
    "\n",
    "batter = batter.drop(1935, axis = 0)\n",
    "\n",
    "batter_conti = batter.drop(['batter_id', 'year', 'year_born', 'batter_name',\n",
    "                            'team', 'position', 'career', 'starting_salary', 'height/weight'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_OPS = batter_conti['OPS']\n",
    "\n",
    "batter_conti_ = batter_conti.drop(['avg', 'OPS', 'SLG', 'OBP'], axis=1)\n",
    "batter_conti_1 = sm.add_constant(batter_conti_, has_constant='add')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습데이터 / 평가데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((332, 20), (143, 20), (332,), (143,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = list(batter_conti_1.columns)\n",
    "\n",
    "X = batter_conti_1[feature_columns]\n",
    "y = target_OPS\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, train_size=0.7, test_size=0.3)\n",
    "train_x.shape, test_x.shape, train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline (Full) 모델 적합 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    OPS   R-squared:                       0.993\n",
      "Model:                            OLS   Adj. R-squared:                  0.992\n",
      "Method:                 Least Squares   F-statistic:                     2394.\n",
      "Date:                Sat, 13 Jun 2020   Prob (F-statistic):          6.42e-323\n",
      "Time:                        23:23:50   Log-Likelihood:                 1086.9\n",
      "No. Observations:                 332   AIC:                            -2136.\n",
      "Df Residuals:                     313   BIC:                            -2064.\n",
      "Df Model:                          18                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.8364      0.028     29.855      0.000       0.781       0.892\n",
      "G             -0.0003   9.69e-05     -3.540      0.000      -0.001      -0.000\n",
      "AB            -0.0017   2.96e-05    -58.201      0.000      -0.002      -0.002\n",
      "R           3.943e-05   6.51e-05      0.605      0.545   -8.88e-05       0.000\n",
      "H              0.0019   7.57e-05     25.215      0.000       0.002       0.002\n",
      "2B             0.0002      0.000      1.539      0.125   -4.39e-05       0.000\n",
      "3B         -6.794e-05      0.000     -0.332      0.740      -0.000       0.000\n",
      "HR          7.826e-05      0.000      0.749      0.454      -0.000       0.000\n",
      "TB             0.0022   4.92e-05     44.026      0.000       0.002       0.002\n",
      "RBI           -0.0001   5.37e-05     -1.986      0.048      -0.000   -9.81e-07\n",
      "SB         -2.192e-06   6.16e-05     -0.036      0.972      -0.000       0.000\n",
      "CS             0.0001      0.000      0.536      0.592      -0.000       0.000\n",
      "BB             0.0013   4.08e-05     30.850      0.000       0.001       0.001\n",
      "HBP            0.0015      0.000     11.818      0.000       0.001       0.002\n",
      "SO          9.301e-07   2.82e-05      0.033      0.974   -5.46e-05    5.65e-05\n",
      "GDP            0.0005      0.000      3.506      0.001       0.000       0.001\n",
      "E          -9.498e-05      0.000     -0.928      0.354      -0.000       0.000\n",
      "Age        -1.718e-05      0.000     -0.112      0.911      -0.000       0.000\n",
      "height         0.0003      0.000      1.559      0.120   -6.67e-05       0.001\n",
      "weight        -0.0002   7.69e-05     -2.213      0.028      -0.000   -1.89e-05\n",
      "==============================================================================\n",
      "Omnibus:                       27.573   Durbin-Watson:                   2.005\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              110.959\n",
      "Skew:                          -0.106   Prob(JB):                     8.05e-25\n",
      "Kurtosis:                       5.824   Cond. No.                     3.83e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 8.05e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "full_model = sm.OLS(train_y, train_x)\n",
    "fitted_full_model = full_model.fit()\n",
    "print(fitted_full_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단계적 선택법을 통한 모델 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSubset(X, y, feature_set):\n",
    "    model = sm.OLS(y, X[list(feature_set)])\n",
    "    regr = model.fit()\n",
    "    AIC = regr.aic\n",
    "    return {'model': regr, 'AIC': AIC}\n",
    "\n",
    "def getBest(X, y, k):\n",
    "    tic = time.time() # 시작시간\n",
    "    results = [] # 결과 저장공간\n",
    "    for combo in itertools.combinations(X.columns.difference(['const']), k): # 각 변수조합을 고려한 경우의 수\n",
    "        combo = (list(combo) + ['const'])\n",
    "        \n",
    "        results.append(processSubset(X, y, feature_set=combo)) # 모델링된 것들을 저장\n",
    "    models = pd.DataFrame(results)\n",
    "    # 가장 낮은 AIC를 가지는 모델 선택 및 저장\n",
    "    best_model = models.loc[models['AIC'].argmin()]\n",
    "    toc = time.time()\n",
    "    print('Processed', models.shape[0], 'models on', k, 'predictors in', (toc - tic), 'seconds')\n",
    "    return best_model\n",
    "\n",
    "def forward(X, y, predictors):\n",
    "    # 데이터 변수들이 미리정의된 predictors에 있는지 없는지 확인 및 분류\n",
    "    remaining_predictors = [p for p in X.columns.difference(['const']) if p not in predictors]\n",
    "    tic = time.time()\n",
    "    results = []\n",
    "    for p in remaining_predictors:\n",
    "        results.append(processSubset(X=X, y= y, feature_set=predictors+[p]+['const']))\n",
    "    # 데이터프레임으로 변환\n",
    "    models = pd.DataFrame(results)\n",
    "\n",
    "    # AIC가 가장 낮은 것을 선택\n",
    "    best_model = models.loc[models['AIC'].argmin()] # index\n",
    "    toc = time.time()\n",
    "    print(\"Processed \", models.shape[0], \"models on\", len(predictors)+1, \"predictors in\", (toc-tic))\n",
    "    print('Selected predictors:',best_model['model'].model.exog_names,' AIC:',best_model[0] )\n",
    "    return best_model\n",
    "\n",
    "def backward(X,y,predictors):\n",
    "    tic = time.time()\n",
    "    results = []\n",
    "    # 데이터 변수들이 미리정의된 predictors 조합 확인\n",
    "    for combo in itertools.combinations(predictors, len(predictors) - 1):\n",
    "        results.append(processSubset(X=X, y= y,feature_set=list(combo)+['const']))\n",
    "    models = pd.DataFrame(results)\n",
    "    # 가장 낮은 AIC를 가진 모델을 선택\n",
    "    best_model = models.loc[models['AIC'].argmin()]\n",
    "    toc = time.time()\n",
    "    print(\"Processed \", models.shape[0], \"models on\", len(predictors) - 1, \"predictors in\",\n",
    "          (toc - tic))\n",
    "    print('Selected predictors:',best_model['model'].model.exog_names,' AIC:',best_model[0] )\n",
    "    return best_model\n",
    "\n",
    "def Stepwise_model(X, y):\n",
    "    Stepmodels = pd.DataFrame(columns=['AIC', 'model'])\n",
    "    tic = time.time()\n",
    "    predictors = []\n",
    "    Smodel_before = processSubset(X, y, predictors+['const'])['AIC']\n",
    "    # 변수 1~10개 : 0~9 -> 1~10\n",
    "    for i in range(1, len(X.columns.difference(['const']))+1):\n",
    "        Forward_result = forward(X=X, y=y, predictors=predictors)\n",
    "        print('forward')\n",
    "        Stepmodels.loc[i] = Forward_result\n",
    "        predictors = Stepmodels.loc[i]['model'].model.exog_names\n",
    "        predictors = [k for k in predictors if k != 'const']\n",
    "        Backward_result = backward(X=X, y=y, predictors=predictors)\n",
    "        if Backward_result['AIC'] < Forward_result['AIC']:\n",
    "            Stepmodels.loc[i] = Backward_result\n",
    "            predictors = Stepmodels.loc[i]['model'].model.exog_names\n",
    "            Smodel_before = Stepmodels.loc[i]['AIC']\n",
    "            predictors = [k for k in predictors if k != 'const']\n",
    "            print('backward')\n",
    "        if Stepmodels.loc[i]['AIC'] > Smodel_before: break\n",
    "        else: Smodel_before = Stepmodels.loc[i]['AIC']\n",
    "        \n",
    "    toc = time.time()\n",
    "    print('Total elapsed time:', (toc - tic), 'seconds')\n",
    "    \n",
    "    return (Stepmodels['model'][len(Stepmodels['model'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed  19 models on 1 predictors in 0.023016929626464844\n",
      "Selected predictors: ['TB', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472de240>\n",
      "forward\n",
      "Processed  1 models on 0 predictors in 0.0017590522766113281\n",
      "Selected predictors: ['const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b37f0>\n",
      "Processed  18 models on 2 predictors in 0.025189876556396484\n",
      "Selected predictors: ['TB', 'AB', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b3400>\n",
      "forward\n",
      "Processed  2 models on 1 predictors in 0.0038230419158935547\n",
      "Selected predictors: ['TB', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8665a7eb8>\n",
      "Processed  17 models on 3 predictors in 0.02134990692138672\n",
      "Selected predictors: ['TB', 'AB', 'H', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a9cc0>\n",
      "forward\n",
      "Processed  3 models on 2 predictors in 0.0050580501556396484\n",
      "Selected predictors: ['TB', 'AB', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b3940>\n",
      "Processed  16 models on 4 predictors in 0.0201263427734375\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b3ac8>\n",
      "forward\n",
      "Processed  4 models on 3 predictors in 0.006688117980957031\n",
      "Selected predictors: ['TB', 'AB', 'H', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a9ac8>\n",
      "Processed  15 models on 5 predictors in 0.01889491081237793\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b3a58>\n",
      "forward\n",
      "Processed  5 models on 4 predictors in 0.008011102676391602\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8665a7da0>\n",
      "Processed  14 models on 6 predictors in 0.01883101463317871\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a94e0>\n",
      "forward\n",
      "Processed  6 models on 5 predictors in 0.0104522705078125\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b39b0>\n",
      "Processed  13 models on 7 predictors in 0.01733088493347168\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a9c88>\n",
      "forward\n",
      "Processed  7 models on 6 predictors in 0.01007986068725586\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a97f0>\n",
      "Processed  12 models on 8 predictors in 0.016299962997436523\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a98d0>\n",
      "forward\n",
      "Processed  8 models on 7 predictors in 0.012977838516235352\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b3c88>\n",
      "Processed  11 models on 9 predictors in 0.015388011932373047\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'CS', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b3ef0>\n",
      "forward\n",
      "Processed  9 models on 8 predictors in 0.01286005973815918\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a9240>\n",
      "Processed  10 models on 10 predictors in 0.014219045639038086\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'CS', 'height', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b38d0>\n",
      "forward\n",
      "Processed  10 models on 9 predictors in 0.014027118682861328\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'CS', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b3748>\n",
      "Processed  9 models on 11 predictors in 0.01405191421508789\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'CS', 'height', 'weight', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b3c50>\n",
      "forward\n",
      "Processed  11 models on 10 predictors in 0.015254020690917969\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a91d0>\n",
      "backward\n",
      "Processed  9 models on 11 predictors in 0.014462947845458984\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'CS', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a9710>\n",
      "forward\n",
      "Processed  11 models on 10 predictors in 0.01598191261291504\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b3898>\n",
      "backward\n",
      "Processed  9 models on 11 predictors in 0.015923023223876953\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'CS', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a9390>\n",
      "forward\n",
      "Processed  11 models on 10 predictors in 0.01607489585876465\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b32b0>\n",
      "backward\n",
      "Processed  9 models on 11 predictors in 0.016025066375732422\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'CS', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a96a0>\n",
      "forward\n",
      "Processed  11 models on 10 predictors in 0.016314268112182617\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472b39b0>\n",
      "backward\n",
      "Processed  9 models on 11 predictors in 0.014647960662841797\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'CS', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a9b70>\n",
      "forward\n",
      "Processed  11 models on 10 predictors in 0.015850067138671875\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a9908>\n",
      "backward\n",
      "Processed  9 models on 11 predictors in 0.014303922653198242\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'CS', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a90f0>\n",
      "forward\n",
      "Processed  11 models on 10 predictors in 0.015466928482055664\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a90b8>\n",
      "backward\n",
      "Processed  9 models on 11 predictors in 0.014286041259765625\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'CS', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8665b2ef0>\n",
      "forward\n",
      "Processed  11 models on 10 predictors in 0.015199899673461914\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a95c0>\n",
      "backward\n",
      "Processed  9 models on 11 predictors in 0.014342784881591797\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'CS', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8665b2320>\n",
      "forward\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed  11 models on 10 predictors in 0.016048192977905273\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8472a9630>\n",
      "backward\n",
      "Processed  9 models on 11 predictors in 0.015167951583862305\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'CS', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8665b2400>\n",
      "forward\n",
      "Processed  11 models on 10 predictors in 0.015181779861450195\n",
      "Selected predictors: ['TB', 'AB', 'H', 'BB', 'HBP', 'G', 'RBI', 'GDP', 'height', 'weight', 'const']  AIC: <statsmodels.regression.linear_model.RegressionResultsWrapper object at 0x7fe8665b26a0>\n",
      "backward\n",
      "Total elapsed time: 0.6473391056060791 seconds\n"
     ]
    }
   ],
   "source": [
    "Stepwise_best_model = Stepwise_model(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    OPS   R-squared:                       0.992\n",
      "Model:                            OLS   Adj. R-squared:                  0.992\n",
      "Method:                 Least Squares   F-statistic:                     5893.\n",
      "Date:                Sat, 13 Jun 2020   Prob (F-statistic):               0.00\n",
      "Time:                        23:23:50   Log-Likelihood:                 1545.2\n",
      "No. Observations:                 475   AIC:                            -3068.\n",
      "Df Residuals:                     464   BIC:                            -3023.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "TB             0.0022   2.83e-05     77.551      0.000       0.002       0.002\n",
      "AB            -0.0017   2.22e-05    -76.370      0.000      -0.002      -0.002\n",
      "H              0.0019   4.66e-05     40.777      0.000       0.002       0.002\n",
      "BB             0.0013   3.02e-05     42.164      0.000       0.001       0.001\n",
      "HBP            0.0015   9.82e-05     14.961      0.000       0.001       0.002\n",
      "G             -0.0004   7.79e-05     -5.238      0.000      -0.001      -0.000\n",
      "RBI           -0.0001    4.2e-05     -2.949      0.003      -0.000   -4.13e-05\n",
      "GDP            0.0004      0.000      3.841      0.000       0.000       0.001\n",
      "height         0.0004      0.000      3.154      0.002       0.000       0.001\n",
      "weight        -0.0002   5.82e-05     -3.215      0.001      -0.000   -7.27e-05\n",
      "const          0.8098      0.023     35.783      0.000       0.765       0.854\n",
      "==============================================================================\n",
      "Omnibus:                       32.888   Durbin-Watson:                   1.749\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              121.942\n",
      "Skew:                           0.110   Prob(JB):                     3.32e-27\n",
      "Kurtosis:                       5.472   Cond. No.                     3.05e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.05e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(Stepwise_best_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_full: 0.00010025794675555962\n",
      "mse_Stepwise: 9.116068912965468e-05\n"
     ]
    }
   ],
   "source": [
    "mse_full = metrics.mean_squared_error(test_y, fitted_full_model.predict(test_x))\n",
    "mse_step = metrics.mean_squared_error(test_y, Stepwise_best_model.predict(test_x[Stepwise_best_model.model.exog_names]))\n",
    "print(f'mse_full: {mse_full}')\n",
    "print(f'mse_Stepwise: {mse_step}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP 모델 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.dense1 = Dense(1024, activation='relu')\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.dense2 = Dense(1024, activation='relu')\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.dense3 = Dense(10, activation='relu')\n",
    "        self.dense4 = Dense(1)\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = tf.keras.layers.Dropout(.5)(x, training=training)\n",
    "        x = self.dense2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = tf.keras.layers.Dropout(.5)(x, training=training)\n",
    "        x = self.dense3(x)\n",
    "        x = self.dense4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((332, 20), (332,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((np.array(train_x), np.array(train_y))).batch(batch_size)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((np.array(test_x), np.array(test_y))).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, datas, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(datas, training=True)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(model, datas, labels, loss_object, test_loss, test_accuracy):\n",
    "    predictions = model(datas, training=False)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model, loss ftn, optimizer, metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "\n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.MeanSquaredError(name='train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.MeanSquaredError(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer mlp is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 1, Loss: 2.2134523391723633, Accuracy 2.2134523391723633, Test Loss: 9.269461631774902, Test Accuracy: 9.269461631774902\n",
      "Epoch 2, Loss: 1.5531426668167114, Accuracy 1.5531426668167114, Test Loss: 6.401004314422607, Test Accuracy: 6.401004314422607\n",
      "Epoch 3, Loss: 1.2762360572814941, Accuracy 1.2762360572814941, Test Loss: 5.746273994445801, Test Accuracy: 5.746273994445801\n",
      "Epoch 4, Loss: 1.0688445568084717, Accuracy 1.0688445568084717, Test Loss: 5.377772331237793, Test Accuracy: 5.377772331237793\n",
      "Epoch 5, Loss: 0.9168587923049927, Accuracy 0.9168587923049927, Test Loss: 4.719537258148193, Test Accuracy: 4.719537258148193\n",
      "Epoch 6, Loss: 0.8040774464607239, Accuracy 0.8040774464607239, Test Loss: 4.041567325592041, Test Accuracy: 4.041567325592041\n",
      "Epoch 7, Loss: 0.7142592072486877, Accuracy 0.7142592072486877, Test Loss: 3.622197151184082, Test Accuracy: 3.622197151184082\n",
      "Epoch 8, Loss: 0.6376491189002991, Accuracy 0.6376491189002991, Test Loss: 3.362966299057007, Test Accuracy: 3.362966299057007\n",
      "Epoch 9, Loss: 0.5753496885299683, Accuracy 0.5753496885299683, Test Loss: 3.089614152908325, Test Accuracy: 3.089614152908325\n",
      "Epoch 10, Loss: 0.5245062112808228, Accuracy 0.5245062112808228, Test Loss: 2.9108781814575195, Test Accuracy: 2.9108781814575195\n",
      "Epoch 11, Loss: 0.4827316403388977, Accuracy 0.4827316403388977, Test Loss: 2.696340322494507, Test Accuracy: 2.696340322494507\n",
      "Epoch 12, Loss: 0.4459671676158905, Accuracy 0.4459671676158905, Test Loss: 2.556457996368408, Test Accuracy: 2.556457996368408\n",
      "Epoch 13, Loss: 0.4151739180088043, Accuracy 0.4151739180088043, Test Loss: 2.4015309810638428, Test Accuracy: 2.4015309810638428\n",
      "Epoch 14, Loss: 0.38814833760261536, Accuracy 0.38814833760261536, Test Loss: 2.260390520095825, Test Accuracy: 2.260390520095825\n",
      "Epoch 15, Loss: 0.36415132880210876, Accuracy 0.36415132880210876, Test Loss: 2.144460439682007, Test Accuracy: 2.144460439682007\n",
      "Epoch 16, Loss: 0.3433505892753601, Accuracy 0.3433505892753601, Test Loss: 2.0662612915039062, Test Accuracy: 2.0662612915039062\n",
      "Epoch 17, Loss: 0.32463538646698, Accuracy 0.32463538646698, Test Loss: 1.978162169456482, Test Accuracy: 1.978162169456482\n",
      "Epoch 18, Loss: 0.3077216148376465, Accuracy 0.3077216148376465, Test Loss: 1.904151439666748, Test Accuracy: 1.904151439666748\n",
      "Epoch 19, Loss: 0.2924571633338928, Accuracy 0.2924571633338928, Test Loss: 1.8305648565292358, Test Accuracy: 1.8305648565292358\n",
      "Epoch 20, Loss: 0.2789052128791809, Accuracy 0.2789052128791809, Test Loss: 1.761986494064331, Test Accuracy: 1.761986494064331\n",
      "Epoch 21, Loss: 0.26650476455688477, Accuracy 0.26650476455688477, Test Loss: 1.6946382522583008, Test Accuracy: 1.6946382522583008\n",
      "Epoch 22, Loss: 0.25500553846359253, Accuracy 0.25500553846359253, Test Loss: 1.6373260021209717, Test Accuracy: 1.6373260021209717\n",
      "Epoch 23, Loss: 0.24443289637565613, Accuracy 0.24443289637565613, Test Loss: 1.579345703125, Test Accuracy: 1.579345703125\n",
      "Epoch 24, Loss: 0.23491981625556946, Accuracy 0.23491981625556946, Test Loss: 1.5235310792922974, Test Accuracy: 1.5235310792922974\n",
      "Epoch 25, Loss: 0.22598989307880402, Accuracy 0.22598989307880402, Test Loss: 1.47238028049469, Test Accuracy: 1.47238028049469\n",
      "Epoch 26, Loss: 0.21778997778892517, Accuracy 0.21778997778892517, Test Loss: 1.4276894330978394, Test Accuracy: 1.4276894330978394\n",
      "Epoch 27, Loss: 0.21013014018535614, Accuracy 0.21013014018535614, Test Loss: 1.384476661682129, Test Accuracy: 1.384476661682129\n",
      "Epoch 28, Loss: 0.20305363833904266, Accuracy 0.20305363833904266, Test Loss: 1.3459941148757935, Test Accuracy: 1.3459941148757935\n",
      "Epoch 29, Loss: 0.19638071954250336, Accuracy 0.19638071954250336, Test Loss: 1.3056590557098389, Test Accuracy: 1.3056590557098389\n",
      "Epoch 30, Loss: 0.19015198945999146, Accuracy 0.19015198945999146, Test Loss: 1.2769086360931396, Test Accuracy: 1.2769086360931396\n",
      "Epoch 31, Loss: 0.18426674604415894, Accuracy 0.18426674604415894, Test Loss: 1.2413835525512695, Test Accuracy: 1.2413835525512695\n",
      "Epoch 32, Loss: 0.17879900336265564, Accuracy 0.17879900336265564, Test Loss: 1.2081751823425293, Test Accuracy: 1.2081751823425293\n",
      "Epoch 33, Loss: 0.17361077666282654, Accuracy 0.17361077666282654, Test Loss: 1.1775003671646118, Test Accuracy: 1.1775003671646118\n",
      "Epoch 34, Loss: 0.16874617338180542, Accuracy 0.16874617338180542, Test Loss: 1.1480646133422852, Test Accuracy: 1.1480646133422852\n",
      "Epoch 35, Loss: 0.16414105892181396, Accuracy 0.16414105892181396, Test Loss: 1.1210893392562866, Test Accuracy: 1.1210893392562866\n",
      "Epoch 36, Loss: 0.15981289744377136, Accuracy 0.15981289744377136, Test Loss: 1.105896234512329, Test Accuracy: 1.105896234512329\n",
      "Epoch 37, Loss: 0.15569619834423065, Accuracy 0.15569619834423065, Test Loss: 1.080212116241455, Test Accuracy: 1.080212116241455\n",
      "Epoch 38, Loss: 0.1518082171678543, Accuracy 0.1518082171678543, Test Loss: 1.056220293045044, Test Accuracy: 1.056220293045044\n",
      "Epoch 39, Loss: 0.1480867862701416, Accuracy 0.1480867862701416, Test Loss: 1.0331814289093018, Test Accuracy: 1.0331814289093018\n",
      "Epoch 40, Loss: 0.1445499062538147, Accuracy 0.1445499062538147, Test Loss: 1.0108771324157715, Test Accuracy: 1.0108771324157715\n",
      "Epoch 41, Loss: 0.14118371903896332, Accuracy 0.14118371903896332, Test Loss: 0.9887494444847107, Test Accuracy: 0.9887494444847107\n",
      "Epoch 42, Loss: 0.13797563314437866, Accuracy 0.13797563314437866, Test Loss: 0.9678200483322144, Test Accuracy: 0.9678200483322144\n",
      "Epoch 43, Loss: 0.13491933047771454, Accuracy 0.13491933047771454, Test Loss: 0.947126030921936, Test Accuracy: 0.947126030921936\n",
      "Epoch 44, Loss: 0.1320008784532547, Accuracy 0.1320008784532547, Test Loss: 0.9282365441322327, Test Accuracy: 0.9282365441322327\n",
      "Epoch 45, Loss: 0.12920285761356354, Accuracy 0.12920285761356354, Test Loss: 0.9095113277435303, Test Accuracy: 0.9095113277435303\n",
      "Epoch 46, Loss: 0.12653353810310364, Accuracy 0.12653353810310364, Test Loss: 0.8916758894920349, Test Accuracy: 0.8916758894920349\n",
      "Epoch 47, Loss: 0.12396690994501114, Accuracy 0.12396690994501114, Test Loss: 0.8738622069358826, Test Accuracy: 0.8738622069358826\n",
      "Epoch 48, Loss: 0.12150708585977554, Accuracy 0.12150708585977554, Test Loss: 0.8572463989257812, Test Accuracy: 0.8572463989257812\n",
      "Epoch 49, Loss: 0.11915000528097153, Accuracy 0.11915000528097153, Test Loss: 0.8416285514831543, Test Accuracy: 0.8416285514831543\n",
      "Epoch 50, Loss: 0.11688213795423508, Accuracy 0.11688213795423508, Test Loss: 0.8261640667915344, Test Accuracy: 0.8261640667915344\n",
      "Epoch 51, Loss: 0.11470722407102585, Accuracy 0.11470722407102585, Test Loss: 0.8111881017684937, Test Accuracy: 0.8111881017684937\n",
      "Epoch 52, Loss: 0.11261924356222153, Accuracy 0.11261924356222153, Test Loss: 0.7967469096183777, Test Accuracy: 0.7967469096183777\n",
      "Epoch 53, Loss: 0.11059927195310593, Accuracy 0.11059927195310593, Test Loss: 0.7841959595680237, Test Accuracy: 0.7841959595680237\n",
      "Epoch 54, Loss: 0.10866119712591171, Accuracy 0.10866119712591171, Test Loss: 0.7712600827217102, Test Accuracy: 0.7712600827217102\n",
      "Epoch 55, Loss: 0.10678917914628983, Accuracy 0.10678917914628983, Test Loss: 0.7584509253501892, Test Accuracy: 0.7584509253501892\n",
      "Epoch 56, Loss: 0.10498779267072678, Accuracy 0.10498779267072678, Test Loss: 0.7461904287338257, Test Accuracy: 0.7461904287338257\n",
      "Epoch 57, Loss: 0.10324462503194809, Accuracy 0.10324462503194809, Test Loss: 0.7342262268066406, Test Accuracy: 0.7342262268066406\n",
      "Epoch 58, Loss: 0.10156872123479843, Accuracy 0.10156872123479843, Test Loss: 0.7221769690513611, Test Accuracy: 0.7221769690513611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59, Loss: 0.0999542772769928, Accuracy 0.0999542772769928, Test Loss: 0.7105911374092102, Test Accuracy: 0.7105911374092102\n",
      "Epoch 60, Loss: 0.09838372468948364, Accuracy 0.09838372468948364, Test Loss: 0.6997751593589783, Test Accuracy: 0.6997751593589783\n",
      "Epoch 61, Loss: 0.09686314314603806, Accuracy 0.09686314314603806, Test Loss: 0.6888818144798279, Test Accuracy: 0.6888818144798279\n",
      "Epoch 62, Loss: 0.0953831672668457, Accuracy 0.0953831672668457, Test Loss: 0.6784348487854004, Test Accuracy: 0.6784348487854004\n",
      "Epoch 63, Loss: 0.09396767616271973, Accuracy 0.09396767616271973, Test Loss: 0.6680673360824585, Test Accuracy: 0.6680673360824585\n",
      "Epoch 64, Loss: 0.0925804153084755, Accuracy 0.0925804153084755, Test Loss: 0.6579773426055908, Test Accuracy: 0.6579773426055908\n",
      "Epoch 65, Loss: 0.0912475734949112, Accuracy 0.0912475734949112, Test Loss: 0.6482732892036438, Test Accuracy: 0.6482732892036438\n",
      "Epoch 66, Loss: 0.0899553969502449, Accuracy 0.0899553969502449, Test Loss: 0.6389220952987671, Test Accuracy: 0.6389220952987671\n",
      "Epoch 67, Loss: 0.0887017548084259, Accuracy 0.0887017548084259, Test Loss: 0.6295282244682312, Test Accuracy: 0.6295282244682312\n",
      "Epoch 68, Loss: 0.08748376369476318, Accuracy 0.08748376369476318, Test Loss: 0.62054443359375, Test Accuracy: 0.62054443359375\n",
      "Epoch 69, Loss: 0.08629976958036423, Accuracy 0.08629976958036423, Test Loss: 0.611770510673523, Test Accuracy: 0.611770510673523\n",
      "Epoch 70, Loss: 0.08514920622110367, Accuracy 0.08514920622110367, Test Loss: 0.6032615303993225, Test Accuracy: 0.6032615303993225\n",
      "Epoch 71, Loss: 0.08406442403793335, Accuracy 0.08406442403793335, Test Loss: 0.5950607061386108, Test Accuracy: 0.5950607061386108\n",
      "Epoch 72, Loss: 0.08298739790916443, Accuracy 0.08298739790916443, Test Loss: 0.5869678854942322, Test Accuracy: 0.5869678854942322\n",
      "Epoch 73, Loss: 0.08192890137434006, Accuracy 0.08192890137434006, Test Loss: 0.5792067646980286, Test Accuracy: 0.5792067646980286\n",
      "Epoch 74, Loss: 0.08090873807668686, Accuracy 0.08090873807668686, Test Loss: 0.5717124342918396, Test Accuracy: 0.5717124342918396\n",
      "Epoch 75, Loss: 0.07991631329059601, Accuracy 0.07991631329059601, Test Loss: 0.5646553635597229, Test Accuracy: 0.5646553635597229\n",
      "Epoch 76, Loss: 0.07894603163003922, Accuracy 0.07894603163003922, Test Loss: 0.5577929019927979, Test Accuracy: 0.5577929019927979\n",
      "Epoch 77, Loss: 0.07799660414457321, Accuracy 0.07799660414457321, Test Loss: 0.5507649779319763, Test Accuracy: 0.5507649779319763\n",
      "Epoch 78, Loss: 0.07707973569631577, Accuracy 0.07707973569631577, Test Loss: 0.5441191792488098, Test Accuracy: 0.5441191792488098\n",
      "Epoch 79, Loss: 0.0761747807264328, Accuracy 0.0761747807264328, Test Loss: 0.5382978916168213, Test Accuracy: 0.5382978916168213\n",
      "Epoch 80, Loss: 0.07528958469629288, Accuracy 0.07528958469629288, Test Loss: 0.5323757529258728, Test Accuracy: 0.5323757529258728\n",
      "Epoch 81, Loss: 0.07442990690469742, Accuracy 0.07442990690469742, Test Loss: 0.526016354560852, Test Accuracy: 0.526016354560852\n",
      "Epoch 82, Loss: 0.07359421998262405, Accuracy 0.07359421998262405, Test Loss: 0.5198186635971069, Test Accuracy: 0.5198186635971069\n",
      "Epoch 83, Loss: 0.07278044521808624, Accuracy 0.07278044521808624, Test Loss: 0.5139816403388977, Test Accuracy: 0.5139816403388977\n",
      "Epoch 84, Loss: 0.07198554277420044, Accuracy 0.07198554277420044, Test Loss: 0.5090816020965576, Test Accuracy: 0.5090816020965576\n",
      "Epoch 85, Loss: 0.07120916247367859, Accuracy 0.07120916247367859, Test Loss: 0.5037094354629517, Test Accuracy: 0.5037094354629517\n",
      "Epoch 86, Loss: 0.07045517861843109, Accuracy 0.07045517861843109, Test Loss: 0.4982425272464752, Test Accuracy: 0.4982425272464752\n",
      "Epoch 87, Loss: 0.06971758604049683, Accuracy 0.06971758604049683, Test Loss: 0.4933531582355499, Test Accuracy: 0.4933531582355499\n",
      "Epoch 88, Loss: 0.06899198889732361, Accuracy 0.06899198889732361, Test Loss: 0.4885118901729584, Test Accuracy: 0.4885118901729584\n",
      "Epoch 89, Loss: 0.06828205287456512, Accuracy 0.06828205287456512, Test Loss: 0.48311224579811096, Test Accuracy: 0.48311224579811096\n",
      "Epoch 90, Loss: 0.06759732961654663, Accuracy 0.06759732961654663, Test Loss: 0.47821539640426636, Test Accuracy: 0.47821539640426636\n",
      "Epoch 91, Loss: 0.06692450493574142, Accuracy 0.06692450493574142, Test Loss: 0.4734744131565094, Test Accuracy: 0.4734744131565094\n",
      "Epoch 92, Loss: 0.0662694200873375, Accuracy 0.0662694200873375, Test Loss: 0.469558984041214, Test Accuracy: 0.469558984041214\n",
      "Epoch 93, Loss: 0.06561838090419769, Accuracy 0.06561838090419769, Test Loss: 0.4654964804649353, Test Accuracy: 0.4654964804649353\n",
      "Epoch 94, Loss: 0.06498950719833374, Accuracy 0.06498950719833374, Test Loss: 0.46174106001853943, Test Accuracy: 0.46174106001853943\n",
      "Epoch 95, Loss: 0.06437183171510696, Accuracy 0.06437183171510696, Test Loss: 0.45802295207977295, Test Accuracy: 0.45802295207977295\n",
      "Epoch 96, Loss: 0.06377026438713074, Accuracy 0.06377026438713074, Test Loss: 0.4544486403465271, Test Accuracy: 0.4544486403465271\n",
      "Epoch 97, Loss: 0.06317351758480072, Accuracy 0.06317351758480072, Test Loss: 0.4514266848564148, Test Accuracy: 0.4514266848564148\n",
      "Epoch 98, Loss: 0.06260443478822708, Accuracy 0.06260443478822708, Test Loss: 0.4473536014556885, Test Accuracy: 0.4473536014556885\n",
      "Epoch 99, Loss: 0.06203601136803627, Accuracy 0.06203601136803627, Test Loss: 0.44316065311431885, Test Accuracy: 0.44316065311431885\n",
      "Epoch 100, Loss: 0.061479322612285614, Accuracy 0.061479322612285614, Test Loss: 0.439972460269928, Test Accuracy: 0.439972460269928\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for datas, labels in train_ds:\n",
    "        train_step(model, datas, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
    "        \n",
    "    for datas, labels in test_ds:\n",
    "        test_step(model, datas, labels, loss_object, test_loss, test_accuracy)\n",
    "    \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(\n",
    "          epoch + 1,\n",
    "          train_loss.result(),\n",
    "          train_accuracy.result(),\n",
    "          test_loss.result(),\n",
    "          test_accuracy.result()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8529148882223112"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9682022"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(model(np.array(test_x)[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8514077739500004"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(fitted_full_model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516730151989939"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Stepwise_best_model.predict(test_x[Stepwise_best_model.model.exog_names]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644    0.812000\n",
      "165     0.888977\n",
      "303     0.831000\n",
      "917     0.774000\n",
      "706     0.891000\n",
      "1420    0.645000\n",
      "2403    0.974531\n",
      "314     0.822000\n",
      "48      0.900000\n",
      "853     0.938000\n",
      "Name: OPS, dtype: float64 tf.Tensor(\n",
      "[[1.4454021 ]\n",
      " [0.81549793]\n",
      " [0.7762311 ]\n",
      " [0.77965975]\n",
      " [0.92071223]\n",
      " [0.7581382 ]\n",
      " [0.9476874 ]\n",
      " [0.7762311 ]\n",
      " [0.80711335]\n",
      " [1.0202705 ]], shape=(10, 1), dtype=float32) 1644    0.801860\n",
      "165     0.886882\n",
      "303     0.823222\n",
      "917     0.774614\n",
      "706     0.897627\n",
      "1420    0.624548\n",
      "2403    0.964871\n",
      "314     0.822992\n",
      "48      0.896128\n",
      "853     0.929856\n",
      "dtype: float64 1644    0.804033\n",
      "165     0.887479\n",
      "303     0.823681\n",
      "917     0.775409\n",
      "706     0.895690\n",
      "1420    0.626991\n",
      "2403    0.963630\n",
      "314     0.823280\n",
      "48      0.896554\n",
      "853     0.929271\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(test_y[:10], model(np.array(test_x)[:10]),\n",
    "     fitted_full_model.predict(test_x)[:10],\n",
    "     Stepwise_best_model.predict(test_x[Stepwise_best_model.model.exog_names])[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6ten2.1",
   "language": "python",
   "name": "py3.6ten2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
